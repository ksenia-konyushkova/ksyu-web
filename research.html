---
title: Research
layout: default
border: science
permalink: /research
---
<h1>Research</h1>

<p>
  This page describes recent research projects, and contains links to the
  relevant papers.
  You might also be interested in <a
  href="https://scholar.google.ch/citations?user=gTACuSgAAAAJ&hl=en">my page on Google Scholar</a>
  or in
  <a href="https://drive.google.com/file/d/0B_d6W7WBDAqGUUNJTVA4SE9uYnc/view">my résumé</a>.
  
</p>

<div class="row row-research">
  <div class="col-xs-12">
    <h2>Learning Active Learning</h2>
  </div>
  <center>
  <p class="subtitle">Learning active learning from real and synthetic data</p>
  </center>
  <div class="col-sm-4">
    
    <img src="img/5.png" class="img-responsive" alt="Active learning for image segmentation">
  </div>
  <div class="col-sm-8">
  
    <p>
We suggest a novel data-driven approach to active learning (AL). The key idea is to train a regressor that predicts the expected error reduction for a candidate sample in a particular learning state. By formulating the query selection procedure as a regression problem we are not restricted to working with existing AL heuristics; instead, we learn strategies based on experience from previous AL outcomes. We show that a strategy can be learnt either from simple synthetic 2D datasets or from a subset of domain-specific data. Our method yields strategies that work well on real data from a wide range of domains.
    </p>
    <ul>
<li>
Learning Active Learning from Real and Synthetic Data.<br>
<strong>K. Konyushkova</strong>, R. Sznitman, P. Fua.<br>
<a href="https://arxiv.org/pdf/1703.03365.pdf" class="btn btn-default btn-xs" role="button">PDF</a>
<a href="https://drive.google.com/file/d/0B_d6W7WBDAqGOHdxMFFfUFUyOXc/view?usp=sharing" class="btn btn-default btn-xs" role="button">poster</a>
</li>
    </ul>
  </div>
</div>

</p>

<div class="row row-research">
  <div class="col-xs-12">
    <h2>How to learn to segment images without laborious annotation?</h2>
  </div>
  <center>
  <p class="subtitle">Active learning for image segmentation</p>
  </center>
  <div class="col-sm-4">
    <img src="img/1.png" class="img-responsive" alt="Active learning for image segmentation">
  </div>
  <div class="col-sm-8">
    <p>
We propose an active learning (AL) approach to training a segmentation classifier that exploits geometric priors to streamline the annotation process in 3D image volumes.
To this end, we use these priors not only to select voxels most in need of annotation but to guarantee that they lie on 2D planar patch, which makes it much easier to annotate than if they were randomly distributed in the volume.
The geometry-inspired AL algorithm is also effective in natural 2D images.
Moreover, an extended version of algorithm is developed for the multi-class segmentation problem.
We evaluated our approach on binary and multi-class segmentation tasks in Electron Microscopy and Magnetic Resonance image volumes, as well as in natural images.
It was demonstrated that the proposed AL approach is capable of dramatically decreasing the amount of tedious labelling for humans.
Comparing our approach against several accepted baselines demonstrates a marked performance increase.
    </p>
    <ul>
<li>
Introducing Geometry in Active Learning for Image Segmentation.<br>
<strong>K. Konyushkova</strong>, R. Sznitman, P. Fua. ICCV 2015.<br>
<a href="http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Konyushkova_Introducing_Geometry_in_ICCV_2015_paper.pdf" class="btn btn-default btn-xs" role="button">PDF</a>
<a href="https://www.youtube.com/watch?v=NTvS2CYjGwc" class="btn btn-default btn-xs" role="button">video</a>
<li>
Geometry in Active Learning for Binary and Multi-class Image Segmentation.<br>
<strong>K. Konyushkova</strong>, R. Sznitman, P. Fua. Submitted to PAMI.<br>
<a href="https://arxiv.org/pdf/1606.09029.pdf" class="btn btn-default btn-xs" role="button">PDF</a>
</li>
    </ul>
  </div>
</div>

<div class="row row-research">
  <div class="col-xs-12">
    <h2>God(s) Know(s): analysing children drawings of God(s)</h2>
  </div>
  <center>
  <p class="subtitle">Developmental and cross-cultural patterns in children drawings of God(s)</p>
  </center>
  <div class="col-sm-4">
    <img src="img/2.png" class="img-responsive" alt="Analyzing children drawings of God">
  </div>
  <div class="col-sm-8">
    <p>
We analyze the database of God (s) drawings by children from different counties, cultural backgrounds and ages.
We detect developmental and cross-cultural patterns in children's drawings of God(s) and other supernatural agents.
We develop methods to objectively evaluate our empirical observations of the drawings with respect to: (1) the gravity center, (2) the average intensities of the colors green and yellow, (3) the use of different colours (palette) and (4) the visual complexity of the drawings.
We find statistically significant differences across ages and countries in the gravity centers and in the average intensities of colors.
These findings support the hypotheses of the experts and raise new questions for further investigation.
    </p>
    <ul>
<li>
God(s) Know(s): Developmental and Cross-Cultural Patterns in Children Drawings.<br>
<strong>K. Konyushkova</strong>, N. Arvanitopoulos, Z. Dandarova Robert, P.-Y. Brandt, S. Süsstrunk. Submitted.<br>
<a href="http://arxiv.org/pdf/1511.03466v2.pdf" class="btn btn-default btn-xs" role="button">PDF</a>
</li>
    </ul>
    <p>
      Media coverage:
    </p>
    <ul>
<li><a
href="https://www.technologyreview.com/s/543676/the-machine-vision-algorithm-for-analyzing-childrens-drawings/">MIT
Technology Review</a></li>
<li><a
href="https://cacm.acm.org/news/194542-the-machine-vision-algorithm-for-analyzing-childrens-drawings/fulltext">Communications of the ACM</a></li>
    </ul>
  </div>
</div>

<div class="row row-research">
  <div class="col-xs-12">
    <h2>Find me what, don't know what</h2>
  </div>
  <center>
  <p class="subtitle">Exploratory search of scientific literature with intent modeling</p>
  </center>
  <div class="col-sm-4">
    <img src="img/3.png" class="img-responsive" alt="Analyzing children drawings of God">
  </div>
  <div class="col-sm-8">
    <p>
One of the most challenging tasks of present-day scientists is making sense of the vast amount of scientific literature.
In this project I worked in a team of researchers on SciNet, an exploratory information seeking system for scientific literature.
SciNet redesigns the query-based search paradigm by combining interactive topical visualization of the information space with a reinforcement learning based user model and search engine.
My role in the project was mostly in reinforcement learning user modeling and evaluation of retrieval performance.
Through the interactive visualization, the system allows users to navigate in the information space by drilling down to more specific content or explore more general content.
The system can assist users even when their goals are uncertain, underspecified, or changing.
We evaluated SciNet with twenty scientists, comparing it to the popular query-based alternative Google Scholar.
SciNet significantly improved the users' information seeking performance, in particular by offering more novel and diverse results while sustaining the overall quality of the results.
    </p>
    <ul>
<li>
Directing exploratory search with interactive intent modeling.<br>
T. Ruotsalo, J. Peltonen, M. Eugster, D. Głowacka, <strong>K. Konyushkova</strong>, K. Athukorala, I. Kosunen, A. Reijonen, P. Myllymäki, G. Jacucci, S. Kaski. CIKM 2013.<br>
<a href="http://dl.acm.org/ft_gateway.cfm?id=2505644&ftid=1411145&dwn=1&CFID=807421810&CFTOKEN=63735394" class="btn btn-default btn-xs" role="button">PDF</a>
</li>
<li>
Supporting exploratory search tasks with interactive user modeling.<br>
T. Ruotsalo, K. Athukorala, D. Głowacka, <strong>K. Konyushkova</strong>, A. Oulasvirta, S. Kaipiainen, S. Kaski, G. Jacucci.
AISTATS 2013.<br>
<a href="http://asis.org/asist2013/proceedings/submissions/papers/29paper.pdf" class="btn btn-default btn-xs" role="button">PDF</a>
</li>
<li>
Scinet: A system for browsing scientific literature through keyword manipulation.<br>
D. Głowacka, T. Ruotsalo, <strong>K. Konyushkova</strong>, K. Athukorala, S. Kaski, G. Jacucci.
IUI 2013.<br>
<a href="http://research.cs.aalto.fi/pml/online-papers/glowacka13iuicomp.pdf" class="btn btn-default btn-xs" role="button">PDF</a>
</li>
<li>
Bayesian Optimization in Interactive Scientific Search<br>
T. Ruotsalo, J. Peltonen, M. Eugster, D. Głowacka, <strong>K. Konyushkova</strong>, K. Athukorala, I. Kosunen, A. Reijonen, P. Myllymäki, G. Jacucci, S. Kaski.
NIPS 2014 workshop on Bayesian Optimization.<br>
<a href="http://bayesopt.github.io/papers/2014/paper14.pdf" class="btn btn-default btn-xs" role="button">PDF</a>
</li>
    </ul>
  </div>

</div>


<div class="row row-research">
  <div class="col-xs-12">
    <h2></h2>
  </div>
  <center>
  <p class="subtitle">Exploratory image retrieval of vaguely defined targets</p>
  </center>
  <div class="col-sm-4">
    <img src="img/4.png" class="img-responsive" alt="Analyzing children drawings of God">
  </div>
  <div class="col-sm-8">
    <p>
We consider a problem of image retrieval in a database of images without matadata such as keywords, tags or natural language text.
In the situation when the user is unable to query the system by context, we employ a mechanism for relevance feedback to specify the information needs.
For instance, imagine a journalist looking for an illustration to his or her article about loneliness in the database of unannotated photos.
The idea of a suitable picture is very vague and the only opportunity for a journalist to navigate is to give relevance feedback to the images proposed by the system.
The system operates through a sequence of rounds, when a set of k images is displayed and the user should indicate which one is the closest to their ideal target image.
    </p>
    <ul>
<li>
Content-based image retrieval with hierarchical Gaussian Process bandits with self-organizing maps.<br>
<strong>K. Konyushkova</strong>, D. Głowacka
ESANN 2013<br>
<a href="https://www.elen.ucl.ac.be/Proceedings/esann/esannpdf/es2013-111.pdf" class="btn btn-default btn-xs" role="button">PDF</a>
</li>
<li>
ImSe: Instant Interactive Image Retrieval System with Exploration/Exploitation trade-off.<br>
<strong>K. Konyushkova</strong>.
M.Sc. thesis, 2013<br>
<a href="https://helda.helsinki.fi/bitstream/handle/10138/39556/Ksenia_ImSe.pdf?sequence=2" class="btn btn-default btn-xs" role="button">PDF</a>
<a href="http://videolectures.net/machine_konyushkova_image_retrieval/" class="btn btn-default btn-xs" role="button">video</a>
<a href="http://www.slideshare.net/NataliaOstapuk/konyushkova" class="btn btn-default btn-xs" role="button">slides</a>
</li>
<li>
ImSe: Instant Interactive Image Retrieval System with Exploration/Exploitation trade-off.<br>
<strong>K. Konyushkova</strong>, D. Głowacka<br>
Russian Summer School in Information Retrieval, 2014<br>
<a href="http://link.springer.com/chapter/10.1007/978-3-319-25485-2_11" class="btn btn-default btn-xs" role="button">PDF</a>
</li>
    </ul>

  </div>
</div>
